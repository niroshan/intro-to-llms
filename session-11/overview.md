# Session 11 — Improve and Evaluate Your Model

## Goal
Make one concrete improvement (training longer, tuning hyperparameters, or switching model type) and evaluate outputs thoughtfully.

## Time
~1 hour

## Key Ideas
- Evaluation can be qualitative (does it look more coherent?) and basic quantitative (loss).
- Small models + small data will still produce errors; that’s expected.

## Learning Outcomes
By the end of this session, the student can:
- Generate multiple samples from the model with different prompts.
- Describe strengths/weaknesses of the output.
- Make a small change and observe its impact.

## Agenda (Suggested)
1. Pick your “main model” (RNN/LSTM/Transformer).
2. Choose one improvement:
   - more training steps
   - different hidden size
   - different sequence length
   - different sampling temperature
3. Generate 3–5 samples.
4. Analyze patterns:
   - real words?
   - punctuation?
   - repeated loops?
   - style mimicry?

## Deliverables
- A short evaluation note saved in Markdown.
- A set of generated samples (with prompts/settings used).

## Stretch (Optional)
- Track loss over time and include a simple plot.

## Reflection Questions
- What is the biggest limitation of your model right now?
- What would you need to improve it dramatically?
