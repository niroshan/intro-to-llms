# Session 7: Quiz

## 1. Gate Understanding
Explain in your own words what the "forget gate" does in an LSTM. Why is it called "forget"?

## 2. Cell State vs Hidden State
An LSTM has both a cell state ($C_t$) and a hidden state ($h_t$). What's the difference in their roles?

## 3. Why Gates Help Gradients
How do gates help solve the vanishing gradient problem?

## 4. LSTM vs GRU
What's the main structural difference between LSTM and GRU? When might you choose one over the other?

## 5. Practical Observation
In the code example, both RNN and LSTM might achieve similar low loss on the training sequence. Why might LSTM still be preferred even when both can "memorize" the training data?
